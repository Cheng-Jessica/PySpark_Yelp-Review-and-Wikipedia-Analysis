# PySpark_Yelp-Review-and-Wikipedia-Analysis with Databricks

## Overview
This Spark SQL and Join Optimization project focuses on various data aggregation and manipulation tasks using two significant real-world datasets. The project involves the analysis of a large Wikipedia Traffic dataset with a network structure (1.2GB / 22 million rows) and a Yelp academic dataset for Yelp Review Analysis (346MB / half-million rows). The Yelp dataset includes information about businesses near universities.

## Datasets
- Yelp Dataset (http://idsdl.csom.umn.edu/c/share/yelp.zip), 128MB compressed, 346MB uncompressed
- Wikipedia Dataset (/databricks-datasets/wikipedia-datasets/data-001/clickstream/raw-uncompressed)

## Main Task in this project
1. Main Goal: Data manipulation and aggregation
2. For Yelp analysis: Use Spark Join Optimization
3. For Wikipedia analysis: Compare DataFrame API approach with the SQL approach.

## How to use
1. Clone the repository to your local machine.
2. Download the Yelp and Wikipedia academic dataset from the provided link.
3. Set up your Spark environment to execute the provided Jupyter Notebooks or scripts.
4. In this project, I use "Databricks" to develop

Contributions are welcome! If you have improvements, optimizations, or additional analyses to suggest, feel free to submit pull requests. Collaboration within the Spark and data analysis community is encouraged.
